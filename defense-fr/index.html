<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->

  <!-- Website verification -->
  
    <meta name="google-site-verification" content="google926ebe556d7434ee.html">
  
  
  <!--
    Avoid warning on Google Chrome Error with Permissions-Policy header:
    Origin trial controlled feature not enabled: 'interest-cohort'.
    see https://stackoverflow.com/a/75119417
  -->
  <meta http-equiv="Permissions-Policy" content="interest-cohort=()">




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      Soutenance de thèse | Anderson Augusma
    
  
</title>
<meta name="author" content="Anderson Augusma">
<meta name="description" content="My personnal website. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <meta name="keywords" content="AI, Deep Learning, Computer Vision, Audio Modeling">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<!-- <link rel="stylesheet" href="/assets/css/mdb.min.css?62a43d1430ddb46fc4886f9d0e3b49b8"> -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->

  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="http://localhost:4000/defense-fr/">

<!-- Dark Mode -->

  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          
            
              <span class="font-weight-bold">Anderson</span>
            
            
            Augusma
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">About
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/publications/">Publications
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/defense/">PhD Defense
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/cv/">CV
                    
                  </a>
                </li>
              
            
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="fa-solid fa-moon"></i>
                <i class="fa-solid fa-sun"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        <div class="post">
  <header class="post-header">
    <h1 class="post-title">Soutenance de thèse</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <!-- Language switch (top-right) -->
<div class="lang-switch">
  <p><a class="btn" href="/defense/">English</a></p>
</div>

<style>
.lang-switch { text-align:right; margin-bottom:0.75rem; }
.lang-switch .btn {
  display:inline-block; padding:0.35rem 0.6rem; border:1px solid #ccc; border-radius:6px;
  text-decoration:none; font-size:0.95rem;
}
.lang-switch .btn:hover { background:#f5f5f5; }
</style>

<!-- French version (translate the blocks you want) -->
<p>
  <strong>Quand :</strong>
  <span id="event-local"></span><br>
  <em>(Heure officielle à Grenoble/Paris : <span id="event-paris"></span>)</em>
</p>

<time id="event-iso" datetime="2026-01-16T13:00:00Z" data-tz="Europe/Paris" data-title="Soutenance de thèse">
  Vendredi 16 janvier 2026, 14:00 (Europe/Paris)
</time>

<script>
  (function () {
    const eventEl = document.getElementById('event-iso');
    const eventUTC = new Date(eventEl.getAttribute('datetime'));
    const parisTZ = eventEl.dataset.tz || 'Europe/Paris';
    const baseOpts = { weekday:'long', year:'numeric', month:'long', day:'numeric', hour:'2-digit', minute:'2-digit' };
    const localStr = new Intl.DateTimeFormat(undefined, baseOpts).format(eventUTC);
    const parisStr = new Intl.DateTimeFormat(undefined, { ...baseOpts, timeZone: parisTZ }).format(eventUTC);
    document.getElementById('event-local').textContent = localStr + ' (heure locale)';
    document.getElementById('event-paris').textContent = parisStr + ' (' + parisTZ + ')';
  })();
</script>

<!--Coming soon ...-->
<p>L’événement aura lieu à l’IMAG (Auditorium de l’IMAG, bâtiment IMAG), 150 Place du Torrent, 38400 Saint-Martin-d’Hères (<a href="https://maps.app.goo.gl/mzt4kJcHUMGf5rdm9" rel="external nofollow noopener" target="_blank">lien Google Maps</a>). Il sera également diffusé en direct via le lien: <a href="https://univ-grenoble-alpes-fr.zoom.us/j/98304379411?pwd=2UuSRh75pbeHg4Iy7pocPLFAxZn8NV.1" rel="external nofollow noopener" target="_blank">zoom link</a>.</p>

<p>La version relue de mon manuscrit de thèse est disponible ici: <a href="../assets/pdf/thesis_anderson.pdf">Lien vers le manuscrit</a>. Il est intitulé: “<em>Reconnaissance des émotions au niveau du groupe en conditions naturelles : vers une approche non individuelle respectueuse de la vie privée</em>”. Le résumé est proposé ci-dessous en anglais, en français et en créole haïtien. La présentation sera donnée en anglais ; les échanges se dérouleront en anglais et en français.</p>

<h1 id="jury">Jury</h1>
<h3 id="rapporteurs">Rapporteurs</h3>
<ul>
  <li>Alessandro VINCIARELLI, Full Professor, University of Glasgow</li>
  <li>Antitza DANTCHEVA, Directrice de Recherche, Centre de l’INRIA Université Côte d’Azur à Sophia Antipolis</li>
</ul>

<h3 id="examinateurs">Examinateurs</h3>
<ul>
  <li>Christine KERIBIN, Professeure des Universités, Université Paris-Saclay</li>
  <li>Bernd DUDZIK, Assistant professor, Delft University of Technology (TU Delft)</li>
  <li>Didier SCHWAB, Professeure des Universités, Université Grenoble Alpes</li>
</ul>

<h3 id="encadrants-de-thèse">Encadrants de Thèse</h3>
<ul>
  <li>Dominique VAUFREYDAZ, Professeur des Universités, Université de Grenoble Alpes</li>
  <li>Frédérique LETUE, Maitresse de Conférence, Université de Grenoble Alpes</li>
</ul>

<h1 id="abstract">Abstract</h1>
<h6 id="version-française-en-dessous"><em>(Version Française en dessous)</em></h6>
<p>This thesis addresses the challenge of group emotion recognition (GER) in-the-wild. Traditional approaches to emotion recognition often rely on individual-level cues such as facial recognition, gaze tracking, or voice profiling. While effective in some settings, these methods raise serious concerns about privacy and surveillance. To overcome these limitations, this thesis prioritizes privacy preservation by leveraging only collective audio–visual signals, focusing on group-level rather than individual-level emotion recognition. The overall objective is to develop multimodal models that can infer group emotions while avoiding the risks associated with individual monitoring and surveillance. Two complementary frameworks are proposed to achieve this goal. The first introduces a cross-attention multimodal architecture for audio–video fusion, combined with a Frames Attention Pooling (FAP) strategy. This framework is further supported by synthetic data augmentation and validated through extensive ablation studies. These experiments demonstrate his effectiveness and robustness for GER in real-world conditions. The second, the Variational Encoder Multi-Decoder (VE-MD), introduces a shared latent space jointly optimized for emotion classification, body, and face structural representation prediction. Two structural representation decoding strategies are explored: DETR-based and heatmap-based, highlighting their respective strengths and limitations in group versus individual settings. A detailed analysis reveals how structural representation integration impacts GER differently compared to non-GER.The scientific contributions of this thesis are threefold. First, it provides new insights into the role of multimodality and structural representation-based cues for group-level affective computing, clarifying how group and individual settings diverge in their requirements and challenges. Second, it advances methodological design through the introduction of two complementary frameworks: a cross-attention fusion model with FAP for temporal aggregation, and VE-MD as a generalizable latent space for multitask learning. Third, it establishes a privacy-preserving paradigm for GER, showing that competitive or state-of-the-art performance can be achieved without relying on individual features as input data.</p>

<h1 id="résumé">Résumé</h1>
<h6 id="vèsyon-kreyòl-ayisyen-an-aprè"><em>(Vèsyon Kreyòl Ayisyen an aprè)</em></h6>

<p>Cette thèse aborde le défi de la reconnaissance des émotions de groupe (GER) en conditions naturelles. Les approches traditionnelles de la reconnaissance des émotions s’appuient souvent sur des indices individuels tels que la reconnaissance faciale, le suivi du regard ou le profilage vocal. Bien qu’efficaces dans certains contextes, ces méthodes soulèvent de sérieuses préoccupations en matière de confidentialité et de surveillance. Pour surmonter ces limites, cette thèse donne la priorité à la préservation de la vie privée en exploitant uniquement des signaux audiovisuels collectifs, se concentrant sur la reconnaissance des émotions au niveau du groupe plutôt qu’au niveau individuel. L’objectif global est de développer des modèles multimodaux capables de déduire les émotions d’un groupe tout en évitant les risques de manipulation et de surveillance individuelle. Deux modélisations complémentaires sont proposées pour atteindre cet objectif. La première introduit une architecture multimodale à attention croisée pour la fusion audio-vidéo, combinée à une stratégie de Frames Attention Pooling (FAP). Cette modélisation est en outre soutenue par l’augmentation des données synthétiques et validée par des études d’ablation approfondies. Ces expériences démontrent son efficacité et sa robustesse pour le GER dans des conditions réelles. La seconde, le Variational Encoder Multi-Decoder (VE-MD), introduit un espace latent partagé optimisé conjointement pour la classification des émotions et la prédiction de la représentation structurelle du corps et du visage. Deux stratégies de décodage de la représentation structurelle sont explorées : celle basée sur DETR  et celle basée sur la carte thermique, mettant en évidence leurs forces et leurs limites respectives dans des contextes de groupe et hors groupe. Une analyse détaillée révèle comment l’intégration de la représentation structurelle a un impact différent sur le GER par rapport au non-GER. Les contributions scientifiques de cette thèse sont triples. Premièrement, elle apporte de nouvelles perspectives sur le rôle de la multimodalité et des indices basés sur la représentation structurelle pour la reconnaissance affective au niveau du groupe, en clarifiant comment les contextes de groupe et individuels divergent dans leurs exigences et leurs défis. Deuxièmement, elle fait progresser la conception méthodologique grâce à l’introduction de deux modélisations complémentaires : un modèle de fusion d’attention croisée avec FAP pour l’agrégation temporelle, et VE-MD comme espace latent généralisable pour l’apprentissage multitâche. Troisièmement, elle établit un paradigme de préservation de la vie privée pour le GER, montrant que des performances compétitives ou de pointe peuvent être obtenues sans s’appuyer sur des caractéristiques individuelles comme des données d’entrée.</p>

<h1 id="rezime">Rezime</h1>

<p>Tèz sa a adrese defi rekonesans emosyon gwoup (GER) nan kondisyon natirèl. Apwòch tradisyonèl yo pou rekonesans emosyon souvan apiye sou siyal endividyèl tankou rekonesans vizaj, swivi je, oswa pwofilaj vwa. Malgre yo efikas nan kèk kontèks, metòd sa yo soulve gwo enkyetid sou vi prive ak siveyans. Pou simonte limitasyon sa yo, tèz sa a bay priyorite ak prezèvasyon vi prive lè li itilize sèlman siyal odyovizyèl kolektif yo. Li konsantre sou rekonesans emosyon gwoup moun ansanm olye chak grenn moun nan group la. Objektif jeneral la se devlope modèl miltimodal (zouti entèlijans atifisyèl) ki kapab rekonèt emosyon gwoup moun pandan y’ap evite risk manipilasyon ak siveyans endividyèl. De apwòch modelizasyon konplemantè pwopoze pou reyalize objektif sila a. Premye a prezante yon achitekti miltimodal atansyon kwaze pou fizyon odyo-videyo, konbine avèk yon estrateji Frames Attention Pooling (FAP). Modèl sa a sipòte pa ogmantasyon done sentetik epi valide pa etid ablasyon divès. Eksperyans sa yo demontre efikasite ak robistès modèl la pou GER nan kondisyon reyèl. Dezyèm nan, Variational Encoder Multi-Decoder (VE-MD), entrodwi yon espas latan pataje optimize ansanm pou klasifikasyon emosyon ak prediksyon reprezantasyon estriktirèl kò ak vizaj moun. Gen de strateji ki eksplore pou dekode reprezantasyon estriktirèl yo: yonn ki baze sou yon modèl DETR ak yonn ki baze sou kat chalè (heatmap), aksan mete sou fòs ak limit respektif yo nan kontèks gwoup ak non-gwoup. Yon analiz detaye revele kijan entegrasyon reprezantasyon estriktirèl yo gen yon enpak diferan sou GER konpare ak sa ki pa GER (non-GER). Kontribisyon syantifik tèz sa a gen twa aspè. Premyèman, li bay yon nouvo apèsi sou wòl miltimodalite ak siyal ki baze sou reprezantasyon estriktirèl pou rekonesans siyal afektif nan nivo gwoup, li klarifye kijan kontèks gwoup ak endividyèl yo divèje nan egzijans ak defi yo. Dezyèmman, li fè pwogrese konsepsyon metodolojik atravè entwodiksyon de modèl konplemantè: yon modèl fizyon atansyon kwaze ak FAP pou agregasyon tanporèl, ak VE-MD kòm yon espas latan jeneralizab pou aprantisaj milti-tach. Twazyèmman, li etabli yon apwòch ki prezève vi prive pou GER, li montre ke pèfòmans konpetitif oswa dènye kri yo ka reyalize san yo pa konte sou karakteristik endividyèl kòm done an antre.</p>

  </article>

  

  
</div>

      
    </div>

    <!-- Footer -->
    
  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      © Copyright 2025
      Anderson
      
      Augusma. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      
      
    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>


    

    

    

    

    

    

    

    

  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>



<!-- Bootstrap Table -->


<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script>
<script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script>
<script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script>

    


    
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
      },
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PRBC4NZY35"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      window.dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PRBC4NZY35');
  </script>



    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


    

    

  </body>
</html>
